{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nimport warnings\nimport plotly.express as px\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom xgboost import XGBClassifier\nimport warnings\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport plotly.offline as offline\nimport plotly.graph_objs as go\n\ntrain = pd.read_csv(\"../input/titanic/test.csv\")\ntest = pd.read_csv(\"../input/titanic/train.csv\")\ndf_data = pd.concat([train, test], sort=True).set_index('PassengerId')","metadata":{"_uuid":"47de0589-2851-43f8-a6c5-b520048f62e9","_cell_guid":"111a07a7-fcbb-43f9-b31a-0fe890733545","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:15.639775Z","iopub.execute_input":"2022-02-21T13:22:15.640224Z","iopub.status.idle":"2022-02-21T13:22:15.666274Z","shell.execute_reply.started":"2022-02-21T13:22:15.640183Z","shell.execute_reply":"2022-02-21T13:22:15.665424Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"df_data.head()","metadata":{"_uuid":"862462bb-0d28-43da-8d65-62e14f4f1a56","_cell_guid":"8701fe26-2b6c-445b-aa28-d8334c077423","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:15.667755Z","iopub.execute_input":"2022-02-21T13:22:15.668200Z","iopub.status.idle":"2022-02-21T13:22:15.685289Z","shell.execute_reply.started":"2022-02-21T13:22:15.668161Z","shell.execute_reply":"2022-02-21T13:22:15.684361Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"# <b>1 <span style='color:#F1C40F'>|</span> Missing Values</b>\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>1.1 | Ticket</b></p>\n</div>\n\nSince data such as the **<span style='color:#F1C40F'>Ticket</span>** is useless, we proceed to drop their columns from the data frame.","metadata":{"_uuid":"9904c5c6-a94e-429e-bbbc-b17ac6030281","_cell_guid":"c9ff432e-53e5-4b2e-97c6-176404b28f6e","trusted":true}},{"cell_type":"code","source":"cols_with_missing = [col for col in df_data.columns if df_data[col].isnull().any()] \npd.isnull(df_data[cols_with_missing]).sum()","metadata":{"_uuid":"bf57e742-2f26-4610-bf4c-5468b689085d","_cell_guid":"adc0d701-f9e6-48fe-b93a-90553db7b65a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:15.691240Z","iopub.execute_input":"2022-02-21T13:22:15.692114Z","iopub.status.idle":"2022-02-21T13:22:15.704712Z","shell.execute_reply.started":"2022-02-21T13:22:15.692071Z","shell.execute_reply":"2022-02-21T13:22:15.704177Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"df_data = df_data.drop(['Ticket'],axis=1)","metadata":{"_uuid":"12c0d8c2-3838-4e6b-83a0-a706d5890691","_cell_guid":"1d16cc05-7a74-42cd-a71a-3ca8940eb27c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:15.708850Z","iopub.execute_input":"2022-02-21T13:22:15.709536Z","iopub.status.idle":"2022-02-21T13:22:15.714139Z","shell.execute_reply.started":"2022-02-21T13:22:15.709504Z","shell.execute_reply":"2022-02-21T13:22:15.713443Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>1.2 | Age</b></p>\n</div>\n\nTo address the problem of missing values for the **<span style='color:#F1C40F'>Age</span>** field we will proceed as follows. Since **<span style='color:#F1C40F'>PClass</span>** is the variable that is **<span style='color:#F1C40F'>most correlated</span>** with both Age and Survived, we will group passengers according to the class they belong to. What we will do is replace the missing values with the **<span style='color:#F1C40F'>median</span>** of each group. In fact, what is more, within each of the existing classes we will make a **<span style='color:#F1C40F'>gender distinction</span>**. We do this because, as we will see below, the median of Age varies according to whether the passenger is male or female.","metadata":{"_uuid":"8dc8eb2b-a88b-449c-b89a-0b95a2b979bb","_cell_guid":"ace4c64f-6841-46da-a4a6-c2124a8645a9","trusted":true}},{"cell_type":"code","source":"df_heatmap = pd.DataFrame(df_data.corr()['Age'].abs())\nf,ax = plt.subplots(figsize=(10,1.5),facecolor='white')\nsns.color_palette(\"rocket\", as_cmap=True)          # Esta paleta es la que viene por defecto\nsns.heatmap(df_heatmap.transpose(),annot = True,square=True, linewidths=1.5, cmap='rocket')","metadata":{"_uuid":"d6b244ea-9a7d-4f6e-8339-0e572b7c29ce","_cell_guid":"110e9013-de96-43f8-b72a-918140f52c5d","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:15.725219Z","iopub.execute_input":"2022-02-21T13:22:15.725954Z","iopub.status.idle":"2022-02-21T13:22:16.000242Z","shell.execute_reply.started":"2022-02-21T13:22:15.725889Z","shell.execute_reply":"2022-02-21T13:22:15.999371Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"mediana = df_data.groupby(['Sex', 'Pclass']).median()['Age']\nfor i in range(0,mediana.shape[0]):\n    if i<3: \n        print('Edad mediana para mujeres de la clase {}: {}'.format(i+1,mediana[i]))\n    else:\n        print('Edad mediana para hombres de la clase {}: {}'.format(i+1-3,mediana[i]))\ndf_data.Age = df_data.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\nprint('Missing values for Age: {}'.format(df_data.Age.isnull().sum()))","metadata":{"_uuid":"e68e01e7-2fb3-4b1b-a868-8e29cfbb6fc7","_cell_guid":"e380d196-7818-4d54-b1af-1269e16f26d1","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.002232Z","iopub.execute_input":"2022-02-21T13:22:16.002724Z","iopub.status.idle":"2022-02-21T13:22:16.024565Z","shell.execute_reply.started":"2022-02-21T13:22:16.002679Z","shell.execute_reply":"2022-02-21T13:22:16.023619Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>1.3 | Embarked</b></p>\n</div>\n\nWith respect to Embarked we will replace the missing data by the **<span style='color:#F1C40F'>mode</span>**, i.e. the most repeated value.","metadata":{"_uuid":"f5831218-bdd0-4c07-a91b-c881a0da46fa","_cell_guid":"0e4aa8b7-d2be-458d-8154-8a11c01ba9c1","trusted":true}},{"cell_type":"code","source":"df_data.Embarked.value_counts()","metadata":{"_uuid":"86c3fe24-c095-445b-afb9-a240133ab760","_cell_guid":"3d64fba4-7cdd-494c-97bc-0a56c2d5f762","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.026157Z","iopub.execute_input":"2022-02-21T13:22:16.026886Z","iopub.status.idle":"2022-02-21T13:22:16.036050Z","shell.execute_reply.started":"2022-02-21T13:22:16.026827Z","shell.execute_reply":"2022-02-21T13:22:16.035198Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"moda = 'S'\ndf_data.Embarked = df_data.Embarked.replace(np.nan,moda)\npd.isnull(df_data).sum()","metadata":{"_uuid":"bee4f600-c06a-4eab-ab88-e7280397f4a5","_cell_guid":"01551fc8-7eb2-4846-9896-cb0bd8c6950a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.038593Z","iopub.execute_input":"2022-02-21T13:22:16.039663Z","iopub.status.idle":"2022-02-21T13:22:16.050218Z","shell.execute_reply.started":"2022-02-21T13:22:16.039619Z","shell.execute_reply":"2022-02-21T13:22:16.049359Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>1.4 | Cabin</b></p>\n</div>\n\n**<span style='color:#F1C40F'>Cabin</span>** feature is little bit tricky and it needs further exploration. The large portion of the Cabin feature is missing and the feature itself **<span style='color:#F1C40F'>can't be ignored completely because some the cabins might have higher survival rates</span>**. It turns out to be the first letter of the Cabin values are the decks in which the cabins are located. Those decks were mainly separated for one passenger class, but some of them were used by multiple passenger classes.\n![alt text](https://vignette.wikia.nocookie.net/titanic/images/f/f9/Titanic_side_plan.png/revision/latest?cb=20180322183733)\n* On the Boat Deck there were **6** rooms labeled as **T, U, W, X, Y, Z** but only the **T** cabin is present in the dataset\n* **A**, **B** and **C** decks were only for 1st class passengers\n* **D** and **E** decks were for all classes\n* **F** and **G** decks were for both 2nd and 3rd class passengers\n* From going **A** to **G**, **<span style='color:#F1C40F'>distance to the staircase increases which might be a factor of survival</span>**","metadata":{"_uuid":"94f41dca-c58c-4972-acf7-75db9bd030ff","_cell_guid":"a6ba6909-fd80-47fa-82fb-d89bf7f9e0e9","trusted":true}},{"cell_type":"code","source":"# Creating Deck column from the first letter of the Cabin column (M stands for Missing)\ndf_data['Deck'] = df_data['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n\ndf_data_decks = df_data.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', \n                                                                        'Fare', 'Embarked', 'Cabin']).rename(columns={'Name': 'Count'}).transpose()\n\ndef get_pclass_dist(df):\n    \n    # Creating a dictionary for every passenger class count in every deck\n    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n    decks = df.columns.levels[0]    \n    \n    for deck in decks:\n        for pclass in range(1, 4):\n            try:\n                count = df[deck][pclass][0]\n                deck_counts[deck][pclass] = count \n            except KeyError:\n                deck_counts[deck][pclass] = 0\n                \n    df_decks = pd.DataFrame(deck_counts)    \n    deck_percentages = {}\n\n    # Creating a dictionary for every passenger class percentage in every deck\n    for col in df_decks.columns:\n        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]\n        \n    return deck_counts, deck_percentages\n\ndef display_pclass_dist(percentages):\n    \n    df_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n    bar_count = np.arange(len(deck_names))  \n    bar_width = 0.85\n    \n    pclass1 = df_percentages[0]\n    pclass2 = df_percentages[1]\n    pclass3 = df_percentages[2]\n    \n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, pclass1, color='#b5ffb9', edgecolor='white', width=bar_width, label='Passenger Class 1')\n    plt.bar(bar_count, pclass2, bottom=pclass1, color='#f9bc86', edgecolor='white', width=bar_width, label='Passenger Class 2')\n    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='#a3acff', edgecolor='white', width=bar_width, label='Passenger Class 3')\n\n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)    \n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)   \n    \n    plt.show()    \n\nall_deck_count, all_deck_per = get_pclass_dist(df_data_decks)\ndisplay_pclass_dist(all_deck_per)","metadata":{"_uuid":"f3862f4c-438f-4160-85e9-1d4bb487ff21","_cell_guid":"40790e68-049b-4d71-93df-1b3c6b79d36f","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.051952Z","iopub.execute_input":"2022-02-21T13:22:16.052421Z","iopub.status.idle":"2022-02-21T13:22:16.352689Z","shell.execute_reply.started":"2022-02-21T13:22:16.052373Z","shell.execute_reply":"2022-02-21T13:22:16.351666Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"📌 **Interpret:** for this graph we'll be grouping by **<span style='color:#F1C40F'>Deck</span>** and **<span style='color:#F1C40F'>PClass</span>** atribute. We are able to appreciate that A,B and C are fully occupied by passengers of 1st class. Moreover, as there is just one person in deck T, which class 1 we are going to group it with deck A. Deck of type D is mainly occupied with 1st class passengers, concretely a 85%. The rest are from 2nd class. To conclude, the remaining decks have all passengers from each of the classes.","metadata":{"_uuid":"64da4470-ff23-4cb4-93e6-a022a669fca3","_cell_guid":"eab58547-7d7d-4615-97f0-de6f4bd95e0f","trusted":true}},{"cell_type":"code","source":"# Passenger in the T deck is changed to A\nidx = df_data[df_data['Deck'] == 'T'].index\ndf_data.loc[idx, 'Deck'] = 'A'","metadata":{"_uuid":"23687894-f329-4ea5-af1c-7f6ea5c54268","_cell_guid":"53d11d3a-cfeb-42ac-93d4-6b3eec2aed1a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.354259Z","iopub.execute_input":"2022-02-21T13:22:16.355201Z","iopub.status.idle":"2022-02-21T13:22:16.362635Z","shell.execute_reply.started":"2022-02-21T13:22:16.355154Z","shell.execute_reply":"2022-02-21T13:22:16.361805Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"df_all_decks_survived = df_data.groupby(['Deck', 'Survived']).count().drop(columns=['Sex', 'Age', 'Fare', \n                                                                                   'Embarked', 'Pclass', 'Cabin']).rename(columns={'Name':'Count'}).transpose()\n\ndef get_survived_dist(df):\n    \n    # Creating a dictionary for every survival count in every deck\n    surv_counts = {'A':{}, 'B':{}, 'C':{}, 'D':{}, 'E':{}, 'F':{}, 'G':{}, 'M':{}}\n    decks = df.columns.levels[0]    \n\n    for deck in decks:\n        for survive in range(0, 2):\n            surv_counts[deck][survive] = df[deck][survive][0]\n            \n    df_surv = pd.DataFrame(surv_counts)\n    surv_percentages = {}\n\n    for col in df_surv.columns:\n        surv_percentages[col] = [(count / df_surv[col].sum()) * 100 for count in df_surv[col]]\n        \n    return surv_counts, surv_percentages\n\ndef display_surv_dist(percentages):\n    \n    df_survived_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M')\n    bar_count = np.arange(len(deck_names))  \n    bar_width = 0.85    \n\n    not_survived = df_survived_percentages[0]\n    survived = df_survived_percentages[1]\n    \n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, not_survived, color='#b5ffb9', edgecolor='white', width=bar_width, label=\"Not Survived\")\n    plt.bar(bar_count, survived, bottom=not_survived, color='#f9bc86', edgecolor='white', width=bar_width, label=\"Survived\")\n \n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Survival Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)    \n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n    plt.title('Survival Percentage in Decks', size=18, y=1.05)\n    \n    plt.show()\n\nall_surv_count, all_surv_per = get_survived_dist(df_all_decks_survived)\ndisplay_surv_dist(all_surv_per)","metadata":{"_uuid":"3727b4e1-4ca8-4274-83f5-947d8022f269","_cell_guid":"bafebb7f-2ccf-44b2-9aa6-11cfa09c29f4","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.364036Z","iopub.execute_input":"2022-02-21T13:22:16.364820Z","iopub.status.idle":"2022-02-21T13:22:16.611125Z","shell.execute_reply.started":"2022-02-21T13:22:16.364774Z","shell.execute_reply":"2022-02-21T13:22:16.610277Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"📌 **Interpret:** for this graph we'll be grouping by **<span style='color:#F1C40F'>Deck</span>** and **<span style='color:#F1C40F'>Survived</span>** atribute, in order to see the survival rate that each Deck has. We are able to appreciate that as expected survival rates are different for every type of Deck. **<span style='color:#F1C40F'>B</span>**, **<span style='color:#F1C40F'>D</span>** and **<span style='color:#F1C40F'>E</span>** are the ones with highest. On the other hand, **<span style='color:#F1C40F'>A</span>** and **<span style='color:#F1C40F'>M</span>** are the ones with lowest. \n\nDue to what we have just seen before, we are going to label decks in the following way: \n* A, B and C decks, as they all have 1st class passengers, are going to be labeled as ABC\n* **D** and **E** decks are labeled as **DE** because both of them have similar passenger class distribution and same survival rate\n* Following the previous criterion we labeled FG\n* M remains equal because it's quite different from the others and it's the one with lowest survival rate.","metadata":{"_uuid":"72481993-2dcc-4f36-8b62-331d6da7681d","_cell_guid":"4d0a195b-fe79-40ff-a224-f5de51104ac2","trusted":true}},{"cell_type":"code","source":"df_data['Deck'] = df_data['Deck'].replace(['A', 'B', 'C'], 'ABC')\ndf_data['Deck'] = df_data['Deck'].replace(['D', 'E'], 'DE')\ndf_data['Deck'] = df_data['Deck'].replace(['F', 'G'], 'FG')\n\ndf_data['Deck'].value_counts()","metadata":{"_uuid":"4e434102-f6c6-478a-a6fa-e3a52771fbc3","_cell_guid":"7bc17312-635e-452a-b6ef-513f6c9aa9f0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.612420Z","iopub.execute_input":"2022-02-21T13:22:16.613123Z","iopub.status.idle":"2022-02-21T13:22:16.625552Z","shell.execute_reply.started":"2022-02-21T13:22:16.613082Z","shell.execute_reply":"2022-02-21T13:22:16.624686Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"df_data = df_data.drop('Cabin',axis=1)\ndf_data.isnull().sum()","metadata":{"_uuid":"9c5196e7-a6e3-4848-a80b-3a7df24fa51b","_cell_guid":"ec013065-66aa-455b-bf31-ea24922a45d8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.627094Z","iopub.execute_input":"2022-02-21T13:22:16.627561Z","iopub.status.idle":"2022-02-21T13:22:16.640446Z","shell.execute_reply.started":"2022-02-21T13:22:16.627517Z","shell.execute_reply":"2022-02-21T13:22:16.639427Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>1.5 | Fare</b></p>\n</div>\n\nWe have one missing value for **<span style='color:#F1C40F'>Fare</span>**, belonging to the test dataset. We are going to fill it with the most repeated value of this field.","metadata":{"_uuid":"b160da6a-5ed0-4b37-8a21-1b996ef61d16","_cell_guid":"bfbd5cbd-9d03-4285-b7d1-6402a9c4cf8c","trusted":true}},{"cell_type":"code","source":"tst = df_data[df_data.Survived.isnull() == True]\nmediana = tst.Fare.describe()[6]\ndf_data.Fare = df_data.Fare.fillna(mediana)","metadata":{"_uuid":"7d7ff17a-2607-4b70-ad49-603f9cde2721","_cell_guid":"68e39312-cb78-4429-b3ab-7ba954597289","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.644756Z","iopub.execute_input":"2022-02-21T13:22:16.645192Z","iopub.status.idle":"2022-02-21T13:22:16.654713Z","shell.execute_reply.started":"2022-02-21T13:22:16.645155Z","shell.execute_reply":"2022-02-21T13:22:16.653744Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"# <b>2 <span style='color:#F1C40F'>|</span> Feature Engineering</b>\n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>2.1 | Family</b></p>\n</div>\n\nWe will start by creating fields related to the family unit. The first of these will come from the **<span style='color:#F1C40F'>SibSp and Parch</span>** fields, which we can remove later. This will reflect the **<span style='color:#F1C40F'>size of passengers' family</span>**. We will also enter a field to indicate whether the passenger is travelling **<span style='color:#F1C40F'>alone</span>** or not.","metadata":{"_uuid":"0e0b3f2a-2294-4d48-842d-0152fe69435f","_cell_guid":"eea47fa9-5852-47ed-82e3-d55803b4cb68","trusted":true}},{"cell_type":"code","source":"df_data['FamilySize'] = df_data.Parch + df_data.SibSp + 1\ndf_data['IsAlone'] = 0\ndf_data.loc[df_data['FamilySize'] == 1, 'IsAlone'] = 1\ndf_data = df_data.drop(['Parch','SibSp'],axis = 1)","metadata":{"_uuid":"caa00454-8b9b-4358-8390-d6a57b29a0c6","_cell_guid":"ea8fa296-1132-482f-a1e4-9288b643d98e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.656113Z","iopub.execute_input":"2022-02-21T13:22:16.656815Z","iopub.status.idle":"2022-02-21T13:22:16.669972Z","shell.execute_reply.started":"2022-02-21T13:22:16.656765Z","shell.execute_reply":"2022-02-21T13:22:16.669288Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>2.2 | Passenger's Name</b></p>\n</div>\n\nNext we are going to add a column that will be, in part, related to the **<span style='color:#F1C40F'>Name</span>** field:","metadata":{}},{"cell_type":"code","source":"df_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T13:22:16.671291Z","iopub.execute_input":"2022-02-21T13:22:16.671874Z","iopub.status.idle":"2022-02-21T13:22:16.690737Z","shell.execute_reply.started":"2022-02-21T13:22:16.671828Z","shell.execute_reply":"2022-02-21T13:22:16.689938Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"df_data['Title'] = df_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\npd.crosstab(df_data['Title'], df_data['Sex']).transpose()","metadata":{"_uuid":"b53e5f16-7e9c-49d6-a6f5-b10823bb4006","_cell_guid":"de81aa8b-3391-4bd8-a03e-1234a03138a3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.692229Z","iopub.execute_input":"2022-02-21T13:22:16.692665Z","iopub.status.idle":"2022-02-21T13:22:16.723016Z","shell.execute_reply.started":"2022-02-21T13:22:16.692624Z","shell.execute_reply":"2022-02-21T13:22:16.722179Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"We can replace many titles with a more common name or classify them as Rare.","metadata":{"_uuid":"4a251896-603e-4066-b1a7-a822a1e605d1","_cell_guid":"6054e82b-1ff3-4918-8457-ac412b068115","trusted":true}},{"cell_type":"code","source":"df_data['Title'] = df_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\ndf_data['Title'] = df_data['Title'].replace('Mlle', 'Miss')\ndf_data['Title'] = df_data['Title'].replace('Ms', 'Miss')\ndf_data['Title'] = df_data['Title'].replace('Mme', 'Mrs')\n\ndf_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().transpose()","metadata":{"_uuid":"956c895d-b1a6-47be-a2c3-9de6e68a184c","_cell_guid":"deaa334e-01a4-46ab-869a-539e5be4f007","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.724457Z","iopub.execute_input":"2022-02-21T13:22:16.724908Z","iopub.status.idle":"2022-02-21T13:22:16.749866Z","shell.execute_reply.started":"2022-02-21T13:22:16.724866Z","shell.execute_reply":"2022-02-21T13:22:16.748994Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>2.3 | Fare</b></p>\n</div>\n\nIn order to binning continuous features we are going to use **<span style='color:#F1C40F'>13 quantile base bins</span>**. Even though the bins are too much, they provide a decent amount of information gain, as it would be seen in next section. We'll create `df_data_no_quart` in order to have a DataFrame with the discrete values of Fare, to make it easier to plotting it later.","metadata":{"_uuid":"145ddda5-1236-46e0-916a-ad9d350f0a19","_cell_guid":"6af06955-080b-45cc-8421-1b58fc1557bf","trusted":true}},{"cell_type":"code","source":"df_data_no_quart = df_data.copy()\nnames = ['1', '2', '3', '4', '5', '6', '7','8','9','10','11','12','13']\ndf_data['Fare'] = pd.qcut(df_data['Fare'], 13, labels = names)\ndf_data.Fare = pd.to_numeric(df_data.Fare, errors = 'coerce')","metadata":{"_uuid":"291e5513-14a4-41cf-b253-cef04d0caae8","_cell_guid":"8d9b7791-a5f1-45b5-b650-046e3a91e7a5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.751530Z","iopub.execute_input":"2022-02-21T13:22:16.751838Z","iopub.status.idle":"2022-02-21T13:22:16.764530Z","shell.execute_reply.started":"2022-02-21T13:22:16.751796Z","shell.execute_reply":"2022-02-21T13:22:16.763707Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>2.4 | Age</b></p>\n</div>\n\nLet's keep binning continuous features. For **<span style='color:#F1C40F'>Age</span>** we are going to use **<span style='color:#F1C40F'>10 quantile base bins</span>**. Even though the bins are too much, they provide a decent amount of information gain, as it would be seen in next section.","metadata":{"_uuid":"209c5919-d2a3-4443-8862-0d2ee65f8086","_cell_guid":"9acc19f6-7383-4bcb-94be-651aa4f09fd8","trusted":true}},{"cell_type":"code","source":"names = ['1','2','3','4','5','6','7','8','9','10']\ndf_data['Age'] = pd.qcut(df_data['Age'], 10, labels = names)","metadata":{"_uuid":"982742e2-bab1-4493-be7d-bfbd0302c77e","_cell_guid":"2484a9dd-4471-4ba6-a13a-20f02f5cae9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.765756Z","iopub.execute_input":"2022-02-21T13:22:16.766379Z","iopub.status.idle":"2022-02-21T13:22:16.773069Z","shell.execute_reply.started":"2022-02-21T13:22:16.766346Z","shell.execute_reply":"2022-02-21T13:22:16.772458Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":"# <b>3 <span style='color:#F1C40F'>|</span> Data Visualization</b>\n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>3.1 | Heat Map</b></p>\n</div>\n\n📌 **Interpret:** On the one hand, the variables with the highest correlations are: **<span style='color:#F1C40F'>PClass</span>** and **<span style='color:#F1C40F'>Fare</span>**. On the other hand, we can appreciate that both, Age and FamilySize are the ones with less correlation coefficient with respect to Survived.","metadata":{"_uuid":"e52e0d93-d046-4b24-9f7f-c95b0b8c8eea","_cell_guid":"5ac712a4-834e-4787-b63e-4f26570202aa","trusted":true}},{"cell_type":"code","source":"df_heatmap = pd.DataFrame(df_data.corr()['Survived'].abs())\nf,ax = plt.subplots(figsize=(16,1.5),facecolor='white')\nsns.color_palette(\"rocket\", as_cmap=True)          # Esta paleta es la que viene por defecto\nsns.heatmap(df_heatmap.transpose(),annot = True,square=True, linewidths=1.5, cmap='rocket')","metadata":{"_uuid":"e1914183-5a5d-4673-9750-1e98d100a0aa","_cell_guid":"66e90317-bdce-4987-b841-58d85591a57e","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:16.774531Z","iopub.execute_input":"2022-02-21T13:22:16.774895Z","iopub.status.idle":"2022-02-21T13:22:17.041671Z","shell.execute_reply.started":"2022-02-21T13:22:16.774851Z","shell.execute_reply":"2022-02-21T13:22:17.040727Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>3.2 | Group of Age Visualization</b></p>\n</div>\n\n📌 **Interpret:** We have created several **<span style='color:#F1C40F'>age groups</span>**, in order to make it easier to make the graphs. On the left size, we have the average fare per each group of age. As observed, **<span style='color:#F1C40F'>older group (48-80)</span>** is the group which has payed more. At the bottom part of the bar graph we can find groups to which teenagers and young adults belong. On the right, I have made a pie plot in order to find which percentage of people from each group survive, and people from which group is more likely to survive. We can see that **<span style='color:#F1C40F'>kids (0.169-16)</span>** are the ones with more survival rate (14.6%). Moreover, we also observe that half of the kids survived. Concretely, a 58.8% of kids survived. On the other hand, older people and youngsters between 21-22 years old bear the brunt as they are the least likely to survive. Indeed, from the whole group of old people just 34% survived aproximately.","metadata":{"_uuid":"ae984ca0-61c8-4aef-873e-3d7e7d4cae89","_cell_guid":"19af3b6b-4cff-442a-a64f-2a2881efbcaa","trusted":true}},{"cell_type":"code","source":"#names = ['0-8', '9-15', '16-18', '19-25', '26-40', '41-60', '61-100']\noneHot_train_graph = df_data_no_quart.copy()\nnames = ['0.169-16','16-21','21-22','22-25','25-26','26-29.5','29.5-34','34-40','40-48','48-80']\noneHot_train_graph['Age'] = pd.qcut(oneHot_train_graph['Age'], 10, labels = names)\ndf_bar = oneHot_train_graph.groupby('Age').agg({'Fare':'mean'}).reset_index().sort_values(by='Fare',ascending=False).set_index('Age')\ndf_pie = oneHot_train_graph.groupby('Age').agg({\"Survived\" : \"mean\"}).reset_index().sort_values(by='Survived', ascending=False).set_index('Age')\n\nfig = make_subplots(rows=1, cols=2, \n                    specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]],                          \n                    column_widths=[0.7, 0.3], vertical_spacing=0, horizontal_spacing=0.02,\n                    subplot_titles=(\"Average Fare per Group of Age\", \"Survival Percentage per Group of Age\"))\n\nfig.add_trace(go.Bar(x=df_bar['Fare'], y=df_bar.index, marker=dict(color=['#334550','#334550','#394184','#394184','#6D83AA','#6D83AA','#C8D0DF','#C8D0DF','#C8D0DF','#C8D0DF']),\n                     name='Fare', orientation='h'), \n                     row=1, col=1)\nfig.add_trace(go.Pie(values=df_pie['Survived'], labels=df_pie.index, name='Age',\n                     marker=dict(colors=['#334550','#334668','#394184','#496595','#6D83AA','#91A2BF','#C8D0DF']), hole=0.7,\n                     hoverinfo='label+percent+value', textinfo='label'), \n                    row=1, col=2)\n# styling\nfig.update_yaxes(showgrid=False, ticksuffix=' ', categoryorder='total ascending', row=1, col=1)\nfig.update_xaxes(visible=False, row=1, col=1)\nfig.update_layout(height=500, bargap=0.2,\n                  margin=dict(b=0,r=20,l=20), xaxis=dict(tickmode='linear'),\n                  title_text=\"Group of Age Analysis\",\n                  template=\"plotly_white\",\n                  title_font=dict(size=29, color='#8a8d93', family=\"Lato, sans-serif\"),\n                  font=dict(color='#8a8d93'), \n                  hoverlabel=dict(bgcolor=\"#f2f2f2\", font_size=13, font_family=\"Lato, sans-serif\"),\n                  showlegend=False)\nfig.show()","metadata":{"_uuid":"3159c96b-235a-4df7-a78f-f7ed4e26d516","_cell_guid":"e6b3a7b7-0027-482e-9351-078faade36a3","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:17.043052Z","iopub.execute_input":"2022-02-21T13:22:17.043302Z","iopub.status.idle":"2022-02-21T13:22:17.311545Z","shell.execute_reply.started":"2022-02-21T13:22:17.043271Z","shell.execute_reply":"2022-02-21T13:22:17.310667Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>3.3 | PClass Visualization</b></p>\n</div>\n\n📌 **Interpret:** for this graph we'll be grouping by **<span style='color:#F1C40F'>PClass</span>** atribute. I have plotted 3 different graphs relating PClass with **<span style='color:#F1C40F'>Title</span>**, **<span style='color:#F1C40F'>Loneliness</span>** and **<span style='color:#F1C40F'>Family Size</span>**. We are able to appreciate that **<span style='color:#F1C40F'>lonely people</span>** have chosen class 3 more than any other. Indeed, both Class 3 and Class 2 have been the preference for more lonely people than accompanied. Class 1 as seen, is more likely to be chosen by people accompanied by one familiar. Families with 3 or more people on board are uniformly distributed between different classes.","metadata":{"_uuid":"cd79dbf2-95b6-4c0e-a16d-63e28a2f57e0","_cell_guid":"8be217c7-9fe1-4975-ab2b-3048ad5ed36f","trusted":true}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(20, 8))\n\nsns.set_style('whitegrid')\nax = sns.countplot(x = \"Pclass\", hue='Title', data = df_data,ax = axes[0], palette=['#334550','#394184','#6D83AA','#91A2BF','#C8D0DF']);\nax.set_title('PClass per Title')\n\nsns.set_style('whitegrid')\nax = sns.countplot(x = \"Pclass\", hue='IsAlone', data = df_data,ax = axes[1], palette=['#334550','#C8D0DF']);\n_ = ax.set_title('PClass per Loneliness')\n\nsns.set_style('whitegrid')\nax = sns.countplot(x = \"Pclass\", hue='FamilySize', data = df_data,ax = axes[2], palette=['#334550','#394184','#6D83AA','#91A2BF','#C8D0DF']);\n__ = ax.set_title('PClass per Family Size')","metadata":{"_uuid":"bada199b-2638-4781-a0b8-cdfec8434dcd","_cell_guid":"ea35cacc-59ca-4e92-afd2-b14e914a2cd2","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:17.312992Z","iopub.execute_input":"2022-02-21T13:22:17.313753Z","iopub.status.idle":"2022-02-21T13:22:18.053985Z","shell.execute_reply.started":"2022-02-21T13:22:17.313716Z","shell.execute_reply":"2022-02-21T13:22:18.053126Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>3.4 | Fare Visualization</b></p>\n</div>\n\n📌 **Interpret:** The groups at the left side of the graph has the lowest survival rate and the groups at the right side of the graph has the highest survival rate. This high survival rate was not visible in the distribution graph. There is also an unusual group (15.742, 23.25] in the middle with high survival rate that is captured in this process.","metadata":{"_uuid":"f8c51835-5bc5-46d4-8755-b341258b5d94","_cell_guid":"9804c0a8-4073-4c8b-834b-b50b3df5fee6","trusted":true}},{"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(22, 9))\nsns.countplot(x='Fare', hue='Survived', data=df_data, palette=['#334550','#C8D0DF'])\n\nplt.xlabel('Fare', size=15, labelpad=20)\nplt.ylabel('Passenger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\n\nplt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\nplt.title('Count of Survival in {} Feature'.format('Fare'), size=15, y=1.05)\n\nplt.show()","metadata":{"_uuid":"a1aeb2e3-aefa-4335-9041-7f5e0a580696","_cell_guid":"a2961e95-ec00-458e-ad28-829c02a8b34c","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:18.055561Z","iopub.execute_input":"2022-02-21T13:22:18.055875Z","iopub.status.idle":"2022-02-21T13:22:18.384829Z","shell.execute_reply.started":"2022-02-21T13:22:18.055834Z","shell.execute_reply":"2022-02-21T13:22:18.383981Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"# <b>4 <span style='color:#F1C40F'>|</span> Categorical Variables</b>\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>4.1 | One Hot Encoding</b></p>\n</div>\n\nWe will now proceed with the oneHot Imputation. With this, we will **<span style='color:#F1C40F'>change the values of the categorical variables to numerical</span>**. This technique comes in handy since both categorical variables have a **<span style='color:#F1C40F'>small</span>** number of unique values.","metadata":{"_uuid":"b1594d2c-a4a7-4f07-8f21-06978c97a517","_cell_guid":"add853a7-7602-412d-8365-0aa2145d73a0","trusted":true}},{"cell_type":"code","source":"df_data.dtypes","metadata":{"_uuid":"aeebcbe6-d3ae-4130-a384-7e0366e7a621","_cell_guid":"24e9e0ed-9d66-44be-badd-f571e441714d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:18.386290Z","iopub.execute_input":"2022-02-21T13:22:18.386592Z","iopub.status.idle":"2022-02-21T13:22:18.395719Z","shell.execute_reply.started":"2022-02-21T13:22:18.386549Z","shell.execute_reply":"2022-02-21T13:22:18.394819Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"print(df_data.Embarked.unique())\nprint(df_data.Sex.unique())","metadata":{"_uuid":"28daafe6-2d80-4400-812a-4d73f6643c50","_cell_guid":"b45bca8e-bed9-4eb9-8c3e-c9ffae4098fc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:18.397266Z","iopub.execute_input":"2022-02-21T13:22:18.397708Z","iopub.status.idle":"2022-02-21T13:22:18.409958Z","shell.execute_reply.started":"2022-02-21T13:22:18.397636Z","shell.execute_reply":"2022-02-21T13:22:18.408988Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"object_cols = [cname for cname in df_data.columns if df_data[cname].dtype == \"object\"]\nobject_cols","metadata":{"_uuid":"878a74f2-2036-4b25-a876-e22204edfa42","_cell_guid":"1f5f0f7e-3bfc-4acc-8b6d-cdcaaffab05e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:18.411326Z","iopub.execute_input":"2022-02-21T13:22:18.411665Z","iopub.status.idle":"2022-02-21T13:22:18.423650Z","shell.execute_reply.started":"2022-02-21T13:22:18.411620Z","shell.execute_reply":"2022-02-21T13:22:18.422783Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_data = pd.DataFrame(OH_encoder.fit_transform(df_data[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_data.index = df_data.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_x_data = df_data.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_data= pd.concat([num_x_data, OH_cols_data], axis=1)","metadata":{"_uuid":"2d984248-8571-49d2-b044-387d0e8ec281","_cell_guid":"aca9a18b-8467-497f-9b35-68eaa6c44c5f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:18.424879Z","iopub.execute_input":"2022-02-21T13:22:18.425222Z","iopub.status.idle":"2022-02-21T13:22:18.473186Z","shell.execute_reply.started":"2022-02-21T13:22:18.425177Z","shell.execute_reply":"2022-02-21T13:22:18.472207Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"OH_data","metadata":{"_uuid":"5b73d38b-098e-4406-8d44-fb1522976668","_cell_guid":"01d6a364-93ff-4d38-b946-efa9675eba1a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:18.474406Z","iopub.execute_input":"2022-02-21T13:22:18.474642Z","iopub.status.idle":"2022-02-21T13:22:18.518986Z","shell.execute_reply.started":"2022-02-21T13:22:18.474612Z","shell.execute_reply":"2022-02-21T13:22:18.518105Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"As we can see, columns **<span style='color:#F1C40F'>0</span>** and **<span style='color:#F1C40F'>1</span>** correspond to the **<span style='color:#F1C40F'>Sex</span>** attribute, while the rest with **<span style='color:#F1C40F'>Embarked</span>**. At this point, we have our dataset ready to be modeled.","metadata":{"_uuid":"cc974b4a-f767-4c6c-99ba-d00c5ff9731d","_cell_guid":"f5ff87eb-c951-4b7f-b723-68873839474b","trusted":true}},{"cell_type":"markdown","source":"# <b>5 <span style='color:#F1C40F'>|</span> Modeling</b>\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>5.1 | Cross Validation</b></p>\n</div>\n\nFor the modeling part we will compare 10 known algorithms, and proceed to evaluate their average accuracy by a **<span style='color:#F1C40F'>stratified kfold cross validation</span>** procedure:\n* SVC\n* Decision Tree\n* AdaBoost\n* Random Forest\n* Extra Trees\n* Gradient Boosting\n* Multiple layer perceprton (neural network)\n* KNN\n* Logistic regression\n* Linear Discriminant Analysis\n* XGBoost Classifier\n\nTo begin with, we are going to create a cross validate model with Kfold stratified. Then we'll test each of the algorithms that I have mentioned before.","metadata":{"_uuid":"a459558b-094b-4e5f-89e0-a37a0b216f0f","_cell_guid":"f076fdec-989a-4aeb-b5c8-2ba68f83ebd4","trusted":true}},{"cell_type":"code","source":"x_train = OH_data[OH_data.Survived.isnull() == False].drop('Survived',axis=1)\ny_train = OH_data[OH_data.Survived.isnull() == False].Survived","metadata":{"_uuid":"1d2743b8-2073-4f0e-af4a-5efd2dbf3736","_cell_guid":"356c07d8-ac38-455e-bea1-d818cda3de75","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:18.520316Z","iopub.execute_input":"2022-02-21T13:22:18.520558Z","iopub.status.idle":"2022-02-21T13:22:18.550469Z","shell.execute_reply.started":"2022-02-21T13:22:18.520527Z","shell.execute_reply":"2022-02-21T13:22:18.549481Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"kfold = StratifiedKFold(n_splits=10)\nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LinearDiscriminantAnalysis())\nclassifiers.append(XGBClassifier(random_state = random_state))\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, x_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n    \ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n    \ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LinearDiscriminantAnalysis\",'XGBClassifier']})\ncv_res = cv_res.sort_values(by='CrossValMeans',ascending = False)","metadata":{"_uuid":"dcf05f00-5dfa-49b0-9378-e2521412b3ba","_cell_guid":"de4a3049-094b-466a-9daa-5cdb6b17ebb6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:22:18.551743Z","iopub.execute_input":"2022-02-21T13:22:18.551994Z","iopub.status.idle":"2022-02-21T13:23:29.967320Z","shell.execute_reply.started":"2022-02-21T13:22:18.551963Z","shell.execute_reply":"2022-02-21T13:23:29.965796Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=1, \n                    specs=[[{\"type\": \"bar\"}]])\n\nfig.add_trace(go.Bar(x=cv_res['CrossValMeans'], y=cv_res.Algorithm, marker=dict(color=['#334550','#334550','#334668','#334668','#496595','#496595','#6D83AA','#6D83AA','#91A2BF','#C8D0DF']),\n                     name='Fare', orientation='h'), \n                     row=1, col=1)\n# styling\nfig.update_yaxes(showgrid=True, ticksuffix=' ', categoryorder='total ascending', row=1, col=1)\nfig.update_xaxes(visible=True, row=1, col=1)\nfig.update_layout(height=500, bargap=0.1,\n                  margin=dict(b=0,r=20,l=20), xaxis=dict(tickmode='linear'),\n                  title_text=\"Cross Validation Scores\",\n                  template=\"plotly_white\",\n                  title_font=dict(size=29, color='#8a8d93', family=\"Lato, sans-serif\"),\n                  font=dict(color='#8a8d93'), \n                  hoverlabel=dict(bgcolor=\"#f2f2f2\", font_size=13, font_family=\"Lato, sans-serif\"),\n                  showlegend=False)\nfig.show()","metadata":{"_uuid":"fa7ac996-c113-4ca4-8f76-55c22ebbfa28","_cell_guid":"6caafbd2-4c05-4932-950a-1060d1742aec","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:23:29.973138Z","iopub.execute_input":"2022-02-21T13:23:29.973718Z","iopub.status.idle":"2022-02-21T13:23:30.055651Z","shell.execute_reply.started":"2022-02-21T13:23:29.973679Z","shell.execute_reply":"2022-02-21T13:23:30.055010Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>5.2 | Hyperparameter tuning</b></p>\n</div>\n\nFor the ensemble modeling we are going to use: \n* ExtraTreesClassifier\n* SVC\n* AdaBoost \n* RandomForest\n* GradientBoosting\nIn order to make execution quicker, we set **<span style='color:#F1C40F'>n_jobs to -1</span>**. This means that we are going to use every CPU we have in the computer.","metadata":{"_uuid":"7da2ffdb-6a60-4c72-8c6f-41b5b49355c6","_cell_guid":"af64bdf8-ef04-4f8f-be8e-8a15c47d4853","trusted":true}},{"cell_type":"code","source":"# Adaboost\nDTC = DecisionTreeClassifier()\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[1,2],\n              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\ngsadaDTC.fit(x_train,y_train)\nada_best = gsadaDTC.best_estimator_\n\n# RFC Parameters tunning \nRFC = RandomForestClassifier()\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\ngsRFC.fit(x_train,y_train)\nRFC_best = gsRFC.best_estimator_\n\n# Gradient boosting tunning\nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1]}\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\ngsGBC.fit(x_train,y_train)\nGBC_best = gsGBC.best_estimator_\n\n# SVC classifier\nSVMC = SVC(probability=True)\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\ngsSVMC.fit(x_train,y_train)\nSVMC_best = gsSVMC.best_estimator_\n\n#ExtraTrees \nExtC = ExtraTreesClassifier()\nex_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\ngsExtC.fit(x_train,y_train)\nExtC_best = gsExtC.best_estimator_","metadata":{"_uuid":"fd0d2ffb-166d-4533-b271-f370003115d6","_cell_guid":"7e1b39d2-b442-411c-be02-eb9c35f5f9d1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:23:30.059415Z","iopub.execute_input":"2022-02-21T13:23:30.059641Z","iopub.status.idle":"2022-02-21T13:42:17.606846Z","shell.execute_reply.started":"2022-02-21T13:23:30.059613Z","shell.execute_reply":"2022-02-21T13:42:17.605958Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>5.3 | Ensemble Modeling and Prediction</b></p>\n</div>\n\nFor the final part of this project I have chosen **<span style='color:#F1C40F'>VotingClassifier</span>**. We'll fit the model and then proceed to make the predictions. At the final part of this section you'll find some graphs related to survival predictions made.","metadata":{"_uuid":"f15c92a0-6bb6-49db-a11d-28bf960cd8ad","_cell_guid":"f56f3cc4-58cb-4c35-b9db-aa7be4acf6ba","trusted":true}},{"cell_type":"code","source":"votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),\n('svc', SVMC_best), ('adac',ada_best),('gbc',GBC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(x_train, y_train)","metadata":{"_uuid":"84a16f1c-caf3-4c02-9279-3e4639ac3f85","_cell_guid":"8106f0af-1a05-44de-a2ce-b1b96a346b15","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:42:17.608462Z","iopub.execute_input":"2022-02-21T13:42:17.609206Z","iopub.status.idle":"2022-02-21T13:42:26.361887Z","shell.execute_reply.started":"2022-02-21T13:42:17.609156Z","shell.execute_reply":"2022-02-21T13:42:26.361172Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"x_test = OH_data[OH_data.Survived.isnull() == True].drop('Survived',axis=1)\nmediana = x_test.Fare.describe()[6]\nx_test.Fare = x_test.Fare.fillna(mediana)\npredictions_survived = votingC.predict(x_test)","metadata":{"_uuid":"8f2fe4b4-a30f-44de-9ad4-19496b012bed","_cell_guid":"4fa18b92-a460-401c-91aa-447dc52e7207","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:42:26.362853Z","iopub.execute_input":"2022-02-21T13:42:26.363130Z","iopub.status.idle":"2022-02-21T13:42:27.790659Z","shell.execute_reply.started":"2022-02-21T13:42:26.363099Z","shell.execute_reply":"2022-02-21T13:42:27.789834Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"predictions = pd.DataFrame({'Survived' : predictions_survived},index = x_test.index)\npredictions['Survived'] = predictions.Survived.astype(int)\npredictions.to_csv('submission.csv')","metadata":{"_uuid":"f676ae4b-131b-4d6f-85ae-9374db5d84f2","_cell_guid":"518fa3d0-b36b-4ca9-bbc1-39daf866962a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:42:27.791980Z","iopub.execute_input":"2022-02-21T13:42:27.792284Z","iopub.status.idle":"2022-02-21T13:42:27.803282Z","shell.execute_reply.started":"2022-02-21T13:42:27.792245Z","shell.execute_reply":"2022-02-21T13:42:27.802581Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"Finally, we will graph the results obtained in order to illustrate the understanding of these results.","metadata":{"_uuid":"e7824e2e-4810-4af9-acbd-fcf40595a18b","_cell_guid":"e5e4b557-f594-4c18-94cf-e43f729967b9","trusted":true}},{"cell_type":"code","source":"x_test_predicted = df_data[df_data.Survived.isnull() == True].copy()\nx_test_predicted['Survived'] = predictions.Survived\ndf_barras_sexo = pd.DataFrame({'Survived':x_test_predicted.Survived, 'Sex':x_test_predicted.Sex, 'Fare':x_test_predicted.Fare,'PClass':x_test_predicted.Pclass,'Age':x_test_predicted.Age,'IsAlone':x_test_predicted.IsAlone,'Title':x_test_predicted.Title})\ndf_barras_sexo['Survived'].replace([0,1], ['No sobrevive','Sobrevive'], inplace=True)\n\nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20, 8))\n\nsns.set_style('whitegrid')\nax = sns.countplot(x = \"Survived\", hue='Sex', data = df_barras_sexo,ax = axes[0],palette=['#334550','#C8D0DF'])\nax.set_title('Cantidad de supervivientes/no supervivientes')\n\nsns.set_style('whitegrid')\nax = sns.barplot(x = \"Survived\", y='Fare', hue = 'Sex', data = df_barras_sexo,ax = axes[1],palette=['#394184','#C8D0DF']);\n_ = ax.set_title('Relación Supervivencia/Tarifa por Sexos')","metadata":{"_uuid":"c7c783dd-af0e-4dfc-a19b-73c75b2523d4","_cell_guid":"14379a14-6198-4f40-837f-955be0f2fc2e","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:42:27.804599Z","iopub.execute_input":"2022-02-21T13:42:27.805102Z","iopub.status.idle":"2022-02-21T13:42:28.374845Z","shell.execute_reply.started":"2022-02-21T13:42:27.805065Z","shell.execute_reply":"2022-02-21T13:42:28.373987Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(22, 11))\n\nsns.set_style('whitegrid')\nax = sns.countplot(x = \"PClass\", hue='Survived', data = df_barras_sexo,ax = axes[0],palette=['#334550','#C8D0DF']);\nax.set_title('Cantidad de supervivientes/no supervivientes según PClass')\n\nsns.set_style('whitegrid')\nax = sns.swarmplot(x = \"Survived\", y='Age', hue = 'Sex', data = df_barras_sexo,ax = axes[1],palette=['#334550','#C8D0DF']);\n_ = ax.set_title('Relación Supervivencia/Edad por Sexos')","metadata":{"_uuid":"0b717977-06cb-4d58-b230-5f1b0b7db2cc","_cell_guid":"6654e9e1-2347-4503-a06b-22db25ab2350","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:42:28.376292Z","iopub.execute_input":"2022-02-21T13:42:28.376610Z","iopub.status.idle":"2022-02-21T13:42:29.343098Z","shell.execute_reply.started":"2022-02-21T13:42:28.376569Z","shell.execute_reply":"2022-02-21T13:42:29.342222Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20, 8))\n\nsns.set_style('whitegrid')\nax = sns.countplot(x = \"Survived\", hue='Title', data = df_barras_sexo,ax = axes[0], palette=['#334550','#394184','#6D83AA','#91A2BF','#C8D0DF']);\nax.set_title('PClass per Title')\n\nsns.set_style('whitegrid')\nax = sns.countplot(x = \"Survived\", hue='IsAlone', data = df_barras_sexo,ax = axes[1], palette=['#334550','#C8D0DF']);\n_ = ax.set_title('PClass per Loneliness')","metadata":{"_uuid":"56a1e449-9fd1-4f54-af90-f1a33c06eb89","_cell_guid":"54f78ff3-7c07-43ec-a994-17a692f5c6f9","collapsed":false,"_kg_hide-input":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-21T13:42:29.344410Z","iopub.execute_input":"2022-02-21T13:42:29.344615Z","iopub.status.idle":"2022-02-21T13:42:29.794451Z","shell.execute_reply.started":"2022-02-21T13:42:29.344590Z","shell.execute_reply":"2022-02-21T13:42:29.793625Z"},"trusted":true},"execution_count":120,"outputs":[]}]}